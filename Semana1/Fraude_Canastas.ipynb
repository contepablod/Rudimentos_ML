{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Colegio Bourbaki](./Images/Bourbaki.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Rudimentos de Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contexto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NP Paribas Personal Finance es líder en financiación personal en Francia y en Europa a través de su actividad de crédito al consumo. Filial al 100% del Grupo BNP Paribas, BNP Paribas Personal Finance reúne a más de 20 000 empleados y opera en una treintena de países. Bajo diversas marcas como Cetelem, Cofinoga y Findomestic, BNP Paribas Personal Finance ofrece a sus clientes una gama completa de créditos al consumo, disponibles en tiendas y concesionarios de automóviles o directamente a través de centros de relación con el cliente y de los sitios web locales de la empresa.\n",
    "\n",
    "BNP Paribas Personal Finance ha desarrollado una estrategia activa de apoyo a los minoristas, fabricantes y concesionarios de automóviles, comerciantes Web y diversas instituciones financieras (banca y seguros), basada en su experiencia en el mercado de crédito y su capacidad para ofrecer servicios adaptados a la actividad y la estrategia comercial de sus socios comerciales. También es un actor clave en materia de crédito responsable y de concienciación presupuestaria.\n",
    "\n",
    "BNPP Personal Finance está, por naturaleza, expuesta al Riesgo de Crédito, y se basa en gran medida en modelos cuantitativos para gestionarlo. Dentro de BNP Paribas Personal Finance, el Departamento Central de Riesgos es responsable de la pertinencia de los modelos de calificación de riesgos utilizados en todas las entidades locales y de mantener un alto nivel de experiencia en la integración de nuevas técnicas estadísticas en nuevos entornos de modelización."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El equipo de Optimización de Procesos de Crédito forma parte del departamento de RIESGO de BNPP PF, dentro de Risk Personal Finance Global Credit Decision-making Policies, contribuimos a la racionalización y la optimización de los procesos de decisión de riesgo a través de un enfoque analítico. Apoyamos a los equipos de riesgo locales para mejorar la eficiencia de los procesos de crédito, incluida la parte de fraude, participando en el mejor equilibrio entre rentabilidad, recorrido del cliente y perfiles de riesgo.\n",
    "\n",
    "**El fraude es un problema importante para los comerciantes. Los delincuentes utilizan una amplia variedad de métodos para atacar a las organizaciones a través de sistemas, canales, procesos y productos. Por ello, el desarrollo de métodos de detección del fraude reviste una importancia crucial. La detección del fraude es un problema difícil porque los defraudadores hacen todo lo posible para que su comportamiento parezca legítimo. Otra dificultad es que el número de registros legítimos es mucho mayor que el número de casos fraudulentos.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**En nuestro caso, trabajeremos con un data ya pre-procesado para poder realizar el modelo de perceptron y regresión logística**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#Classificaon\n",
    "from sklearn.linear_model import Perceptron , LogisticRegression\n",
    "\n",
    "#Utils\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones de ayuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def high_correlation_features(dataframe, threshold=0.95):\n",
    "    \"\"\"\n",
    "    Identifies and returns pairs of highly correlated features from the given dataframe.\n",
    "\n",
    "    Parameters:\n",
    "    - dataframe: A pandas DataFrame containing the dataset.\n",
    "    - threshold: A float representing the correlation threshold to identify high correlations.\n",
    "\n",
    "    Returns:\n",
    "    - A DataFrame with pairs of features that have a correlation coefficient above the threshold.\n",
    "    \"\"\"\n",
    "    # Calculate the correlation matrix\n",
    "    corr_matrix = dataframe.corr()\n",
    "\n",
    "    # Find features with a correlation above the threshold\n",
    "    # Note: The matrix is symmetric, so we need to filter out one side to avoid duplicates\n",
    "    high_corr_pairs = (corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "                       .stack()\n",
    "                       .reset_index())\n",
    "    high_corr_pairs.columns = ['Feature 1', 'Feature 2', 'Correlation']\n",
    "    high_corr_pairs = high_corr_pairs.loc[high_corr_pairs['Correlation'] > threshold, :]\n",
    "\n",
    "    return high_corr_pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_highly_correlated_features(dataframe, threshold=0.95):\n",
    "    \"\"\"\n",
    "    Removes features that are highly correlated with each other above a specified threshold.\n",
    "\n",
    "    Parameters:\n",
    "    - dataframe: A pandas DataFrame containing the dataset.\n",
    "    - threshold: A float representing the correlation threshold to identify high correlations.\n",
    "\n",
    "    Returns:\n",
    "    - A DataFrame with the highly correlated features removed.\n",
    "    \"\"\"\n",
    "    # Calculate the correlation matrix\n",
    "    corr_matrix = dataframe.corr().abs()\n",
    "    \n",
    "    # Select upper triangle of correlation matrix\n",
    "    upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    \n",
    "    # Find features with correlation greater than the threshold\n",
    "    to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > threshold)]\n",
    "    \n",
    "    # Drop features \n",
    "    reduced_df = dataframe.drop(to_drop, axis=1)\n",
    "    \n",
    "    return reduced_df, to_drop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_correlation_matrix(dataframe, plot_graph=True, return_matrix=False):\n",
    "    \"\"\"\n",
    "    Calculates and optionally plots the correlation matrix of a given DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    - dataframe: DataFrame from which to calculate the correlation matrix.\n",
    "    - plot_graph: If True, displays a heatmap of the correlation matrix.\n",
    "    - return_matrix: If True, returns the correlation matrix.\n",
    "    \n",
    "    Returns:\n",
    "    - If return_matrix is True, returns the correlation matrix of the dataframe.\n",
    "    \"\"\"\n",
    "    # Calculate the correlation matrix\n",
    "    correlation_matrix = dataframe.corr('spearman')\n",
    "    \n",
    "    # Plot the correlation matrix heatmap if requested\n",
    "    if plot_graph:\n",
    "        plt.figure(figsize=(25, 20))\n",
    "        sns.heatmap(correlation_matrix, vmin=-1, vmax=1, center=0, cmap=\"hot\", annot=True, fmt=\".2f\", square=True)\n",
    "        plt.xticks(rotation=45, horizontalalignment='right')\n",
    "    \n",
    "    # Return the correlation matrix if requested\n",
    "    if return_matrix:\n",
    "        return correlation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Plots a confusion matrix using Seaborn's heatmap.\n",
    "\n",
    "    Parameters:\n",
    "    - y_true: array-like of shape (n_samples,), True labels of the data.\n",
    "    - y_pred: array-like of shape (n_samples,), Predicted labels.\n",
    "\n",
    "    Returns:\n",
    "    - None, displays a confusion matrix.\n",
    "    \"\"\"\n",
    "    # Compute confusion matrix\n",
    "    confusion_mat = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    # Create a DataFrame for Seaborn's heatmap\n",
    "    confusion_df = pd.DataFrame(confusion_mat, index=['Real Negative', 'Real Positive'], columns=['Predicted Negative', 'Predicted Positive'])\n",
    "    \n",
    "    # Plotting the heatmap\n",
    "    plt.figure(figsize=(10,7))\n",
    "    sns.heatmap(confusion_df, annot=True, fmt='g', cmap='Blues')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('Actual Values')\n",
    "    plt.xlabel('Predicted Values')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(clf, X_test, y_test, figsize=(10, 7)):\n",
    "    \"\"\"\n",
    "    Plots the ROC curve by handling classifiers with or without the `predict_proba` method.\n",
    "    Uses `decision_function` or binary predictions as fallbacks.\n",
    "    \n",
    "    Parameters:\n",
    "    - clf: Classifier to evaluate.\n",
    "    - X_test: Test data features.\n",
    "    - y_test: True labels for the test data.\n",
    "    - figsize: Size of the plot.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # First try to use predict_proba\n",
    "        y_scores = clf.predict_proba(X_test)[:, 1]\n",
    "    except AttributeError:\n",
    "        try:\n",
    "            # Next, try to use decision_function\n",
    "            y_scores = clf.decision_function(X_test)\n",
    "            # Convert decision scores to probabilities (min-max scaling)\n",
    "            y_scores = (y_scores - y_scores.min()) / (y_scores.max() - y_scores.min())\n",
    "        except AttributeError:\n",
    "            # As a last resort, use binary predictions\n",
    "            # This approach lacks precision and should be used cautiously\n",
    "            y_pred = clf.predict(X_test)\n",
    "            y_scores = np.where(y_pred == 1, 1, 0)  # Assuming the positive class is labeled as 1\n",
    "\n",
    "    # Calculate ROC curve and AUC\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_scores)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    # Plotting\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.plot(fpr, tpr, label=f\"ROC curve (area = {roc_auc:.2f})\")\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('./drive/MyDrive/Data/FraudeCanastas.csv') #Colab\n",
    "df = pd.read_csv('./Data/FraudeCanastas.csv') #Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index('ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Los valores nulos son {sum(df.isnull().sum())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of the fraud flag\n",
    "fraud_distribution = df['fraud_flag'].value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fraud_flag'].plot(kind='hist')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a ver correlaciones entre las caracteristicas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#high_corr_features_df = high_correlation_features(df, 0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reduced_df, _ = remove_highly_correlated_features(df, 0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separar las etiquetas del conjunto de datos\n",
    "X = df.drop('fraud_flag', axis=1)\n",
    "y = df['fraud_flag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    shuffle=True,\n",
    "                                                    random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imprime los conjuntos de entrenamiento y prueba\n",
    "print(\"TRAINING SET\")\n",
    "print(\"X: \", X_train.shape)\n",
    "print(\"y: \", y_train.shape)\n",
    "print('Fraude:{:7.3f}%'.format(y_train.mean()*100),'\\n')\n",
    "\n",
    "print(\"TEST SET\")\n",
    "print(\"X: \", X_test.shape)\n",
    "print(\"y: \", y_test.shape)\n",
    "print('Fraude:{:7.3f}%'.format(y_test.mean()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a entrenar un Perceptrón:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Perceptron(max_iter=100, random_state=42, verbose=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train,y_train)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos las métricas del modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Precisión conjunto entrenamiento: %.2f%%\" % (model.score(X_train, y_train)*100.0))\n",
    "print(\"Precisión conjunto prueba: %.2f%%\" % (model.score(X_test, y_test)*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos ahora la clasificación con Perceptron con margen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_margin = Perceptron(penalty='l2', max_iter=100, random_state=42, verbose=True, alpha=0.00005) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_margin.fit(X_train,y_train)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_margin.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Precisión conjunto entrenamiento: %.2f%%\" % (model_margin.score(X_train, y_train)*100.0))\n",
    "print(\"Precisión conjunto prueba: %.2f%%\" % (model_margin.score(X_test, y_test)*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve(model_margin, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_margin_1 = Perceptron(penalty='l2', max_iter=100, random_state=42, verbose=True, alpha=0.0005) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_margin_1.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_margin_1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve(model_margin_1, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Precisión conjunto entrenamiento: %.2f%%\" % (model_margin_1.score(X_train, y_train)*100.0))\n",
    "print(\"Precisión conjunto prueba: %.2f%%\" % (model_margin_1.score(X_test, y_test)*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_margin_2 = Perceptron(penalty='l2', max_iter=100, random_state=42, verbose=True, alpha=0.005) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_margin_2.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_margin_2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve(model_margin_2, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Precisión conjunto entrenamiento: %.2f%%\" % (model_margin_2.score(X_train, y_train)*100.0))\n",
    "print(\"Precisión conjunto prueba: %.2f%%\" % (model_margin_2.score(X_test, y_test)*100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejercicios:\n",
    "\n",
    "* Realizar feature selection\n",
    "\n",
    "* Optimizar el modelo del Perceptron.  Optar por la regularización L1 o L2.\n",
    "\n",
    "* Comenzar el challenge desde cero y realizar el prepocesamiento. No necesariamente tienen que llegar al mismo preprocesamiento usado. Pueden tomar sus decisiones de compromiso como así lo deseen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Lenguaje Matemático](./Images/Matematicas.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Contacto](./Images/Contacto.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
